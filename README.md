# âš¡ï¸ Global Active Power Consumption Prediction

> A Machine Learning Pipeline for Smart Energy Forecasting

---

## ğŸ“ˆ Project Summary

This project aims to build an end-to-end machine learning system to **predict global active power consumption** using time-series data. It involves:

âœ… Data understanding & exploration  
âœ… Preprocessing and feature engineering  
âœ… Regression model development  
âœ… Model evaluation and comparison  

---

## ğŸ§  Problem Statement

With growing energy demand, accurate forecasting of power consumption is essential for:

- Reducing energy waste
- Optimizing energy grid operations
- Power-aware infrastructure planning

**Goal:** Predict `Global_active_power` using regression models based on historical usage and other engineered features.

---

## ğŸ“¦ Dataset Overview

| Feature | Description |
|--------|-------------|
| Date & Time | Timestamp of power consumption |
| Global_active_power | Target variable (kW) |
| Sub_metering_1/2/3 | Energy usage by different appliances |
| Voltage | Average voltage per minute |
| Global_intensity | Average current per minute |

> ğŸ“ *Optional External Data*: Weather conditions (e.g., temperature, humidity)

---

## ğŸ” Exploratory Data Analysis (EDA)

- ğŸ“Š Trend & seasonality plots
- ğŸ“ˆ Correlation heatmaps
- ğŸ“¦ Outlier detection using boxplots
- ğŸ“‰ Time-series decomposition

---

## ğŸ”§ Data Preprocessing Steps

- âœ… Missing value treatment (interpolation, imputation)
- â³ Date/Time parsing into `hour`, `day`, `month`, etc.
- ğŸ§® Feature creation:
  - Rolling means
  - Peak hours
  - Daily averages
- ğŸ“ Feature scaling with MinMaxScaler / StandardScaler

---

## ğŸ— Feature Engineering

- ğŸ¯ Relevant feature selection based on correlation and importance
- ğŸŒ¦ Weather integration (if available)
- ğŸ” Lag features and rolling windows for temporal context

---

## ğŸ¤– Model Building

| Model | Type |
|-------|------|
| ğŸ”¹ Linear Regression | Baseline |
| ğŸŒ² Random Forest | Tree-based ensemble |
| ğŸš€ Gradient Boosting (XGBoost/LightGBM) | Advanced ensemble |
| ğŸ§  Neural Networks (MLP) | Deep learning approach |

**Hyperparameter tuning** using `GridSearchCV` and `RandomizedSearchCV`.

---

## ğŸ§ª Model Evaluation

| Metric | Purpose |
|--------|---------|
| ğŸ§® RMSE | Penalizes larger errors |
| ğŸ“‰ MAE | Average absolute error |
| ğŸ“ˆ RÂ² Score | Variance explained by the model |

ğŸ“Š **Visualization:** Actual vs Predicted line plots, residual distribution, and error curves.

---

## ğŸ† Results Summary

- âœ”ï¸ Best model: `Gradient Boosting Regressor` (example)
- ğŸ“Š RMSE: 0.192 | MAE: 0.137 | RÂ²: 0.91
- ğŸ” Found strong temporal patterns & peak hour influence

---

## ğŸš€ Future Enhancements

- ğŸ“¡ Real-time dashboard using Streamlit / Power BI
- â± LSTM-based deep learning for sequence prediction
- ğŸŒ¦ External weather + holiday/event data fusion

---

## ğŸ—‚ Project Structure

```bash
.
â”œâ”€â”€ data/                  # Raw and processed datasets
â”œâ”€â”€ notebooks/             # EDA and modeling notebooks
â”œâ”€â”€ src/                  # Python scripts for modular code
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ model_training.py
â”œâ”€â”€ report/                # Evaluation reports, charts
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
# House-hold-power-consumption
